
# java数据结构
## 1.HashMap：数组长度为什么到64才会转成红黑树,什么时候树化？什么时候resize() 啊？
## 2.HashMap扩容为什么是乘2
* 扩容后，数据迁移时，数据要么在原来的位置，要么在原来的位置+扩容长度，不需要重新hash--效率更好。
* “与”操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。h&（length-1）
## 3.HashMap扩容机制、底层数据结构
### 扩容时间
* JDK1.7  
1.判断是否到达阈值（0.75x数组长度）  
2.同时判断是否产生hash冲突(就是要插入位置上是否有元素）  
3.扩容后，再添加元素  
* JDK1.8  
1.先添加元素  
2.判断是否达到阈值  
### 扩容方法
* JDK1.7  
1.使用头插法  
2.使用单向链表进行数据迁移  
* JDK1.8  
1.使用尾插法  
2.使用单向链表或者红黑树进行数迁移  
* HashMap设定初始容量大小为大于k的2的整数次方  
默认为16，如果传入初始大小k，初始化为大于k的2次幂数字  
### 解决hash冲突
1.开放定址法  
2.重hash  
3.溢出区  
4.拉链法(hashmap选择）  
### 扰动函数
* hash函数是先拿到通过key 的hashcode，是32位的int值，然后让hashcode的高16位和低16位进行异或操作
* 降低hash碰撞，越分散越好
* 位运算效率高
* 利用高位和低位的特征，防止因为低位影响导致hash碰撞增多
* (h=key.hashcode())^(h>>>16)
* Java1.8-1次位移，一次异或 ；jdk1.7 4次
## 4. 为什么桶集合选择数组啊
* 数组通过元素的KEY的hash值定位寻找的效率很高，扩容大小也是可以定，容易取模定位
## 5. 讲讲HashMap底层原理
## 6. Map有哪些实现类，HashMap为什么是线程不安全的？
1. 在多线程环境下，1.7 会产生死循环、数据丢失、数据覆盖的问题，1.8 中会有数据覆盖的问题。
## 7. HashMap put get 等操作理想的时间复杂度是多少，回答 O(1)，那为了达到O(1) hashmap做了哪些优化？ 回答了一些减少hash碰撞的因素包括调节负载因子啥的，不太满意，让我从设计者的角度说。
## 8. 既然提到hash碰撞，hash值如何计算的？如果key不是基本类型或string类型而是个对象呢？怎么重写hashcode()方法？如果key是个集合呢？
## 9. hashmap为什么线程不安全？提到了1.7之前的头插法，追问了句头插法为什么会导致死循环过程了解吗。尾插法相对于头插法有什么优势？那为什么之前一直使用头插法？
1. hashmap没有用锁，多线程都可以同时操作  
2. 头插法导致死循环：因为在resize阶段，如果有两个线程同时resize，会导向前后节点next相互指向，因为resize其实会导致链表顺序逆转，所以如果一般已经逆转，一边没有（但是已经拿到原始的当前值和next），导致变成循环链表。  
3. 尾插法优势不会导致循环链表 
4. 之前使用头插法是考虑了刚插入的数据可能是热点数据，利用率会高  
## 10. 那对比一下 ConcurrentHashMap 和 HashTable，为什么前者性能更好，只回答了锁粒度和get不加锁两方面，被追问，不会。那这两个分别用在什么场景？
1. HashTable是直接在操作方法上加synchronized关键字，锁住整个数组，粒度比较大；  
2. Collections.synchronizedMap是使用Collections集合工具的内部类，通过传入Map封装出一个SynchronizedMap对象，内部定义了一个对象锁，方法内通过对象锁实现；  
3. ConcurrentHashMap使用分段锁，降低了锁粒度，让并发度大大提高。  
## 11. ConcurrentHashMap如何实现线程安全的？
1. ConcurrentHashMap成员变量使用volatile 修饰，免除了指令重排序，同时保证内存可见性  
2. 另外使用CAS操作和synchronized结合实现赋值操作，多线程操作只会锁住当前操作索引的节点。  
## 12. ConcurrentHashMap怎么分的段?
## 13. ConcurrentHashMap ：1.7/1.8区别，然后size和get无法强一致性之类
1. put()方法中 初始化数组大小时，1.8不用加锁，因为用了个 sizeCtl 变量，将这个变量置为-1，就表明table正在初始化。  
2. 去除 Segment + HashEntry + Unsafe 的实现，  
3. 改为 Synchronized + CAS + Node + Unsafe 的实现  
4. 其实 Node 和 HashEntry 的内容一样，但是HashEntry是一个内部类。  
5. 用 Synchronized + CAS 代替 Segment ，这样锁的粒度更小了，并且不是每次都要加锁了，CAS尝试失败了在加锁。  
6. 无法强一致性表现为，只对put加锁，get没有，导致可能拿不到最新数据  
## 14. ArrayList和LinkedList的底层原理是什么样的，它们有什么区别，具体的使用场景是什么样的？
## 15. String的hashcode怎么计算的
## 16. 那先说一下 ArrayList主要的成员变量、常用方法。说一下扩容机制。
## 17. string、stringBuffer、stringBuilder的区别


# JVM
## 1.怎么判断是可回收对象？
* 可达性分析算法，从GCroot出发，到达堆内每个可达对象，如果到达不了证明已经没有引用，可以回收了
##  可达性分析根节点是怎么来的？
* 所有不在堆内的对象，或者新生代的GCroot可以用老年代的对象（本地方法栈内的引用对象，方法区静态属性引用的对象，方法区的常量引用对象之类，基础数据类型对应的类对象，异常对象）
##  JVM内存模型
* PC寄存器：记录这个程序运行到哪里（因为多线程切换，不可能一直到底）
* 栈：每个线程都有自己栈，只有进栈出栈，没有GC，运行程序指示地方
* 本地方法栈
* 堆：新生区，一般new对象都放这里，除非放不下（比如经过minorgc还不够空间，或者对象比新生区还大，每次minrogc会把eden区对象放到survior）；养老区：放置大，或者时间久的对象（majorGC）
* 方法区：共享区域，常量池（字节码）运行地方，包含类信息，域，方法之类
##  堆中的划分结构
* 老年代：放置大对象和比较久的对象（判断比较久为经历了多次minorGC，有个计数器）
* 新生代：一般new对象都会放置在这里
1.eden区：80%生死  
2.survivor区：minorgc进入，有两个区域，用复制算法，复制一次+1，次数到了去老年代  
##  对象的回收过程
* 先用可达性算法从GCroot标记那些可以触及对象，然后对不可触及活对象进行回收，非存活对象有两种状态，有可复活，不可触及，如果可复活会调用finalize进行复活，只能复活一次，然后对不可触及进行回收
##  有哪些垃圾回收算法以及优缺点
* 标记_清除算法 ：从根节点出发，标记可达对象，不可达对象会被标记为空闲（会导致内存地址不连续，需要维护一个标记空闲列表的）
* 复制算法：一般用在survivor区，速度比较快，但是消耗内存太大，一般要两倍
* 标记_压缩算法：从根节点出发，标记可达对象，再按顺序一个一个排列，优势是不会导致地址不连续，缺点是时间消耗太久，对于大对象比较有优势
* 分代收集算法：根据新生代老年代不同特性区回收
* 增量收集算法：每次总是回收一小片区域，然后切回来，这样会导致用户延迟少，但是吞吐量下降
* 分区算法：每次收集一小块区域，比如把新生代分为几十个区，再一个一个回收，速度比较快
##  高吞吐量该jvm如何调优
* 减少GC次数，增大每次GC时间
##  在线长多线程发生oom时，怎么进行排除，有没有什么好用的工具
##  垃圾回收器（CMS和G1）介绍，分别在哪些代
* CMS（老年代使用，并发垃圾回收器）
1.STW单线程标记GCroot =》 并发标记 =》 STW并发重新确认 =》并发垃圾清理  
2.低延迟，会产生碎片，无法处理浮动垃圾  
* G1
1. 并发：可以与主程序交替进行，并行，几个GC一起发生  
2. 分代收集，总体是标记压缩算法，但是对于每个region是复制算法  
3.可以预测的停顿时间模型，可以根据每次停顿时间来控制回收的大小  
4.回收过程：年轻代Eden用尽，  
##  介绍下MinorGC
* 一般发生在年轻代，当年轻代空间满了，或者对象太大放不下去会触发minorGC，对年轻代没有引用的垃圾进行回收，剩下会放入survivor区，然后survivor区会一共两个区，会将有对象区复制到没有对象的区，而且会年龄标记增加1
##  新生代的回收算法是什么
* 一般使用复制算法，因为内存空间小，但是希望速度快，所以复制算法比较合适
##  对象年龄计算的方法
* 可以设置，默认15，在survivor中fromto就增加1次，到达15就去老年代
##  在老年代中怎么判断对象是否能回收
* 可达性分析算法，从GCroot出发，到达堆内每个可达对象，如果到达不了证明已经没有引用，可以回收了
##  什么对象会作为GC root节点
* 虚拟机中栈引用的对象
* 本地方法栈中JNI的对象
* 方法区的静态属性引用对象
* 方法区中常量引用对象
* 所有被同步锁持有的对象
* 虚拟机的内部引用
##  jvm垃圾回收机制？
##  jvm内存中，堆和栈的区别？


# 多线程和锁
## 1. 线程有哪几种创建方式？Thread，runable，callable，各自的区别。
1. 继承Thread类，可以直接调用start()启动，有单继承的限制。
2. 实现Runnable接口，必须借助Thread对象的start()启动，实现接口可以解决单继承限制问题。
3. 使用ExecutorService、Callable（FutureTask去实现）、Future实现有返回结果的多线程
## 2.   synchronized锁升级过程
### 1. 因此在使用synchronized同步锁的时候需要进行用户态到内核态的切换（所以上锁很浪费资源）
### 2. 在JDK1.5之前，synchronized是重量级锁，1.6以后对其进行了优化，有了一个 无锁-->偏向锁-->自旋锁-->重量级锁 的锁升级的过程
### 3. 对于重量锁来说，一旦线程获取失败，就要陷入阻塞状态，并且是操作系统层面的阻塞，这个过程涉及用户态到核心态的切换，是一个开销非常大的操作
### 4. 在Java虚拟机中，普通对象在内存中分为三块区域：对象头、实例数据、对齐填充数据
	1. 对象头包括markword（8字节）和类型指针（开启压缩指针4字节，不开启8字节，如果是32g以上内存，都是8字节） 
	2. 实例数据就是对象的成员变量  
	3. adding就是为了保证对象的大小为8字节的倍数，将对象所占字节数补到能被8整除   
### 5. synchronized升级  
#### 1. 无锁态   
	偏向锁位、锁标志位的值为：0 01，此时对象是没有做任何同步限制   
#### 2. 偏向锁  
	偏向锁位、锁标志位的值为：1 01  
	其核心思想就是：一个线程获取到了锁，那么锁就会进入偏向模式，当同一个线程再次请求该锁的时候，无需做任何同步，直接进行同步区域执行。这样就省去了大量有关锁申请的操作。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果。  
#####  偏向锁加锁过程  
1. 访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。    
2. 如果为可偏向状态，则判断线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。    
3. 如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。  
4. 如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。  
5. 执行同步代码。  
* 偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。
#####  偏向锁的适用场景
* 始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁。在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向锁的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用。所以一般JVM并不是一开始就开启偏向锁的，而是有一定的延迟，这也就是为什么会有无锁态的原因。可以使用-XX:BiasedLockingStartupDelay=0来关闭偏向锁的启动延迟, 也可以使用-XX:-UseBiasedLocking=false来关闭偏向锁。偏向锁撤销导致的stw
* 通过加偏向锁的方式可以看到，对象中记录了获取到对象锁的线程ID，这就意味如果短时间同一个线程再次访问这个加锁的同步代码或方法时，该线程只需要对对象头Mark Word中去判断一下是否有偏向锁指向它的ID，有的话就继续执行逻辑了，没有的话，会CAS尝试获得锁，如果持有锁的线程在全局安全点检查时，不需要再使用该锁了则获取成功，程序继续执行，反之则获取锁失败，撤销偏向状态，升级为轻量级锁，即自旋锁。
#### 3. 轻量级锁（自旋锁）
* 当有另外一个线程竞争获取这个锁时，由于该锁已经是偏向锁，当发现对象头 Mark Word 中的线程 ID 不是自己的线程 ID，销偏向锁状态，将锁对象markWord中62位修改成指向自己线程栈中Lock Record的指针（CAS抢）执行在用户态，消耗CPU的资源（自旋锁不适合锁定时间长的场景、等待线程特别多的场景），此时锁标志位为：00。
#####  自旋策略
* JVM 提供了一种自旋锁，可以通过自旋方式不断尝试获取锁，从而避免线程被挂起阻塞。这是基于大多数情况下，线程持有锁的时间都不会太长，毕竟线程被挂起阻塞可能会得不偿失。
* 自适应自旋锁
* JDK 1.6引入了更加聪明的自旋锁，叫做自适应自旋锁。他的自旋次数是会变的，我用大白话来讲一下，就是线程如果上次自旋成功了，那么这次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么这次自旋也很有可能会再次成功。反之，如果某个锁很少有自旋成功，那么以后的自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。 大家现在觉得没这么low了吧。
#####  轻量级锁的加锁过程：
1. 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。
2. 拷贝对象头中的Mark Word复制到锁记录中；
3. 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word中的62位更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。  
4. 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态。  
5. 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。此时为了提高获取锁的效率，线程会不断地循环去获取锁, 这个循环是有次数限制的, 如果在循环结束之前CAS操作成功, 那么线程就获取到锁, 如果循环结束依然获取不到锁, 则获取锁失败, 对象的MarkWord中的记录会被修改为指向互斥量（重量级锁）的指针，锁标志的状态值变为10，线程被挂起，后面来的线程也会直接被挂起。
#####  轻量级锁的释放
* 释放锁线程视角：由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。因为重量级锁被修改了，所有display mark word和原来的markword不一样了。
* 怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。
* 尝试获取锁线程视角：如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。
* 从 JDK1.7 开始，自旋锁默认启用，自旋次数由 JVM 设置决定，这里我不建议设置的重试次数过多，因为 CAS 重试操作意味着长时间地占用 CPU。自旋锁重试之后如果抢锁依然失败，同步锁就会升级至重量级锁，锁标志位改为 10。在这个状态下，未抢到锁的线程都会进入 Monitor，之后会被阻塞在 WaitSet 队列中。    
#### 4. 重量级锁
*  此时锁标志位为：10。前面我们提到的markWord，若是重量锁，对象头中还会存在一个监视器对象，也就是Monitor对象。这个Monitor对象就是实现synchronized的一个关键。
* 在Java虚拟机(HotSpot)中，Monitor对象其实就是ObjectMonitor对象，这个对象是一个C++对象，定义在虚拟机源码中。
#####  ObjectMonitor有比较多的属性，但是比较重要的属性有四个：  
1. count：计数器。用来记录获取锁的次数。该属性主要用来实现重入锁机制。
2. owner：记录着当前锁对象的持有者线程。
3. WaitSet：队列。当一个线程调用了wait方法后，它会释放锁资源，进入WaitSet队列等待被唤醒。
4. EntryList：队列。里面存放着所有申请该锁对象的线程。
#####  所以一个线程获取锁对象的流程如下：
1. 判断锁对象的锁标志位是重量级锁，于是想要获取Monitor对象锁。
2. 如果Monitor中的count属性是0，说明当前锁可用，于是把 owner 属性设置为本线程，然后把 count 属性+1。这就成功地完成了锁的获取。
3. 如果Monitor中的count属性不为0，再检查 owner 属性，如果该属性指向了本线程，说明可以重入锁，于是把 count 属性再加上1，实现锁的冲入。
4. 如果 owner 属性指向了其他线程，那么该线程进入 EntryList 队列中等待锁资源的释放。
5. 如果线程在持有锁的过程中调用了wait()方法，那么线程释放锁对象，然后进入 WaitSet 队列中等待被唤醒。
#### 5. synchronized的执行过程：
1. 检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁
2. 如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1
3. 如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。
4. 当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁
5. 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。
6. 如果自旋成功则依然处于轻量级状态。
7. 如果自旋失败，则升级为重量级锁。
#### 6.. 减小锁的粒度
1. 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间（如ConcurrentHashMap、LinkedBlockingQueue、LongAdder）；
#### 7. 锁粗化
1. 大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度; 在以下场景下需要粗化锁的粒度：
2. 假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；
## 3. 线程池有几种创建的方式（我只知道ExecuterThreadPool...，就介绍这个）  
### 通过Executer去创建：
#### 1. newCachedThreadPool（）
		 它是用来处理大量短时间工作任务的线程池，具有几个鲜明特点：它会试图缓存线程并重用，当无缓存线程可用时，就会创建新的工作线程；如果线程闲置时间超过60秒，则被终止并移除缓存；长时间闲置时，这种线程池，不会消耗什么资源。其内部使用SynchronousQueue作为工作队列。
#### 2. newFixedThreadPool（int nThreads）
		 重用指定数目（nThreads）的线程，其背后使用的是无界的工作队列，任何时候最多有nThreads个工作线程是活动的。这意味着，如果任务数量超过了活动线程数目，将在工作队列中等待空闲线程出现；如果工作线程退出，将会有新的工作线程被创建，以补足指定数目nThreads。
#### 3. newSingleThreadExecutor()
		 它的特点在于工作线程数目限制为1，操作一个无界的工作队列，所以它保证了所有的任务都是被顺序执行，最多会有一个任务处于活动状态，并且不予许使用者改动线程池实例，因此可以避免改变线程数目。
#### 4. newSingleThreadScheduledExecutor()和newScheduledThreadPool(int corePoolSize)
		创建的是个ScheduledExecutorService，可以进行定时或周期性的工作调度，区别在于单一工作线程还是多个工作线程。
#### 5. newWorkStealingPool(int parallelism)
		其内部会构建ForkJoinPool，利用Work-Stealing算法，并行地处理任务，不保证处理顺序。
#### 6. Executors 返回线程池对象的弊端如下：
		 FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。
		 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM
### ThreadPoolExecutor构造函数
#### 1. ThreadPoolExecutor 3 个最重要的参数：
	* corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。
	* maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
	* workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
#### 2. ThreadPoolExecutor其他常见参数:
	* keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
	* unit : keepAliveTime 参数的时间单位。
	* threadFactory :executor 创建新线程的时候会用到。
	* handler : 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，ThreadPoolTaskExecutor 定义一些策略:
	* ThreadPoolExecutor.AbortPolicy： 抛出 RejectedExecutionException来拒绝新任务的处理。
	* ThreadPoolExecutor.CallerRunsPolicy： 调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。
		* ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。
		* ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。
## 4. 多线程下的数组会发生哪些问题？怎么解决？
1. 线程不安全
## 5. 介绍CopyOnWriteArrayList，有什么缺点？有加锁吗？
## 6. 线程池怎么实现的
## 7. 你对信号量了解吗，乐观锁和悲观锁有什么看法
## 8. 读写锁了解不，要是有一文件一直被读写占用，写锁请求不到怎么办
## 9. 公平、非公平加锁说下？可以用这俩解决上述问题吗，怎么做
## 10. ConcurrentHashMap 如何保证线程安全的？
## 11. 并发编程了解哪些？ 互斥锁、线程池、阻塞队列啥的都了解一些。说了一下线程池参数被打断。
## 12. 聊一下互斥锁，这里说了Reentrantlock，公平锁和非公平锁，底层是sync实现的AQS。
## 13. 讲一下AQS，以非公平锁为例，让说一下A,B,C三个线程请求资源到释放资源这个过程AQS都发生了啥。状态啥的都记不太清了，靠脑补。中间说了句非公平锁的线程会先通过CAS尝试获取资源，问比较并交换判断的是什么，没答上来。
## 14. 阻塞队列了解吗？会一点点。如果线程池阻塞队列的大小设置的很小，是用于什么样的场景？不会。会用阻塞队列写生产消费模型吗？一会儿写一下。
## 15. Java中NIO知道吗
## 16. NIO和BIO的区别
## 17. synchronized、lock、volatile的区别
## 18. 死锁形成的原因以及解决死锁的方法,怎样避免死锁  
## 19. 如何创建一个线程？使用线程设置堆大小？
## 20. Java线程池中的构造参数有那几个
## 21. poolsize为2 maxpoolsize为4 ,放入3个线程会怎么样


 
# 其他


## 1. Maven开发工具如果出现不同项目里同一个包的版本冲突怎么办
## 2. 为什么使用拉链法解决冲突啊？
## 3. java容器有什么、哪些是线程安全的
## 4. Object类都有哪些方法
## 5. hashcode函数的作用是什么
## 6. 哈希冲撞有哪些解决办法
## 7. Objects类中的通用方法？其中hashCode方法的返回值是什么？
## 8. 子类可以继承父类所有的成员，但是对private这样的，没有访问权

